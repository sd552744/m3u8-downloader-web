import os
import requests
import m3u8
import threading
import queue
import time
import json
import shutil
from urllib.parse import urljoin, urlparse
from Crypto.Cipher import AES
import hashlib
from typing import Optional, Dict, List, Callable
import tempfile
import logging
import subprocess
import sys
import random

logger = logging.getLogger(__name__)

class M3U8Downloader:
    """M3U8ä¸‹è½½å™¨ - é«˜æ€§èƒ½ç‰ˆæœ¬"""
    
    def __init__(self, task_id: str, url: str, save_path: str, 
                 max_threads: int = 10,  # é»˜è®¤æ”¹ä¸º10çº¿ç¨‹
                 cookies: Optional[Dict] = None, proxy: Optional[Dict] = None):
        self.task_id = task_id
        self.url = url
        self.save_path = save_path
        self.max_threads = min(max_threads, 20)  # é™åˆ¶æœ€å¤§20çº¿ç¨‹
        self.is_stopped = False
        self.is_paused = False
        
        # ä¸‹è½½é€Ÿåº¦è·Ÿè¸ª
        self.downloaded_bytes = 0
        self.start_time = time.time()
        self.current_speed = 0
        
        # AES è§£å¯†ç›¸å…³
        self.key = None
        self.iv = None
        
        # åˆ›å»ºä¼šè¯ - ä½¿ç”¨è¿æ¥æ± å’Œæ›´ä¼˜çš„é…ç½®
        self.session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10,  # å‡å°‘è¿æ¥æ•°
            pool_maxsize=50,      # å‡å°‘æœ€å¤§è¿æ¥
            max_retries=2
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
        
        # å¢å¼ºçš„é€šç”¨ User-Agent åˆ—è¡¨
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
        
        # å¢å¼ºçš„é˜²ç›—é“¾åŸŸåé…ç½®
        self.domain_headers = {
            'modujx10.com': {
                'Referer': 'https://play.modujx10.com/',
                'Origin': 'https://play.modujx10.com'
            },
            'example.com': {
                'Referer': 'https://example.com/',
                'Origin': 'https://example.com'
            }
        }
        
        if cookies:
            self.session.cookies.update(cookies)
        if proxy:
            self.session.proxies.update(proxy)

    def _get_random_user_agent(self) -> str:
        """è·å–éšæœº User-Agent"""
        return random.choice(self.user_agents)

    def _get_domain_headers(self, url: str) -> Dict:
        """æ ¹æ®åŸŸåè·å–ç‰¹å®šçš„è¯·æ±‚å¤´"""
        headers = {
            'User-Agent': self._get_random_user_agent(),
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }
        
        parsed_url = urlparse(url)
        domain = parsed_url.netloc
        
        for config_domain, config_headers in self.domain_headers.items():
            if config_domain in domain:
                headers.update(config_headers)
                break
        else:
            headers['Referer'] = f"{parsed_url.scheme}://{domain}/"
            headers['Origin'] = f"{parsed_url.scheme}://{domain}"
        
        return headers

    def _get_ffmpeg_path(self) -> Optional[str]:
        """è·å–FFmpegè·¯å¾„"""
        if shutil.which('ffmpeg'):
            return 'ffmpeg'
        return None

    def download_with_retry(self, url: str, max_retries: int = 3, timeout: int = 15):
        """å¸¦é‡è¯•çš„ä¸‹è½½ - å¢å¼ºé˜²ç›—é“¾æ”¯æŒ"""
        for i in range(max_retries):
            if self.is_stopped:
                return None
                
            try:
                headers = self._get_domain_headers(url)
                
                start_time = time.time()
                resp = self.session.get(url, timeout=timeout, headers=headers)
                resp.raise_for_status()
                
                content = resp.content
                content_size = len(content)
                
                # æ›´æ–°ä¸‹è½½ç»Ÿè®¡
                self.downloaded_bytes += content_size
                download_time = time.time() - start_time
                
                if download_time > 0:
                    self.current_speed = content_size / download_time
                
                return content
                
            except Exception as e:
                logger.warning(f"ä¸‹è½½å¤±è´¥ (å°è¯• {i+1}/{max_retries}): {str(e)}")
                if i < max_retries - 1:
                    time.sleep(1)
                else:
                    raise
        return None

    def load_key(self, key_uri: str, base_uri: str):
        """åŠ è½½AESå¯†é’¥"""
        if not key_uri:
            return
            
        key_url = key_uri if key_uri.startswith('http') else urljoin(base_uri, key_uri)
        key_content = self.download_with_retry(key_url)
        if key_content:
            self.key = key_content
            print(f"âœ… å¯†é’¥åŠ è½½æˆåŠŸï¼Œé•¿åº¦: {len(key_content)} bytes")

    def decrypt_ts(self, data: bytes, segment) -> bytes:
        """è§£å¯†TSåˆ†ç‰‡"""
        if not self.key:
            return data
            
        # è·å–IV
        if segment.key and segment.key.iv:
            iv = bytes.fromhex(segment.key.iv.replace("0x", ""))
        else:
            seq = getattr(segment, 'media_sequence', 0) or 0
            iv = seq.to_bytes(16, byteorder='big')
        
        # AESè§£å¯†
        cipher = AES.new(self.key, AES.MODE_CBC, iv)
        return cipher.decrypt(data)

    def download_segments(self, segments: List, base_uri: str, temp_dir: str, 
                         progress_callback: Optional[Callable] = None) -> bool:
        """ä¸‹è½½åˆ†ç‰‡ - æ”¯æŒæ–­ç‚¹ç»­ä¼ """
        # æ£€æŸ¥ä¸´æ—¶ç›®å½•ä¸­å·²ä¸‹è½½çš„æ–‡ä»¶
        existing_files = set()
        if os.path.exists(temp_dir):
            for f in os.listdir(temp_dir):
                if f.endswith('.ts') and f.replace('.ts', '').isdigit():
                    existing_files.add(int(f.replace('.ts', '')))
        
        task_queue = queue.Queue()
        
        # åªä¸‹è½½æœªå®Œæˆçš„åˆ†ç‰‡
        for i, segment in enumerate(segments):
            if i not in existing_files:
                filename = f"{i:05d}.ts"
                task_queue.put((i, segment, filename))
        
        total_segments = len(segments)
        downloaded_segments = len(existing_files)
        total_tasks = task_queue.qsize()
        
        if downloaded_segments > 0:
            print(f"ğŸ”„ å‘ç° {downloaded_segments} ä¸ªå·²ä¸‹è½½åˆ†ç‰‡ï¼Œç»§ç»­ä¸‹è½½å‰©ä½™ {total_tasks} ä¸ªåˆ†ç‰‡")
        
        completed_tasks = 0
        lock = threading.Lock()
        last_progress_update = 0
        
        def worker():
            nonlocal completed_tasks, last_progress_update
            while not self.is_stopped and not task_queue.empty():
                while self.is_paused and not self.is_stopped:
                    time.sleep(0.5)
                
                try:
                    i, segment, filename = task_queue.get(timeout=1)
                except queue.Empty:
                    break
                
                try:
                    seg_url = segment.absolute_uri or urljoin(base_uri, segment.uri)
                    ts_data = self.download_with_retry(seg_url)
                    
                    if ts_data:
                        if self.key:
                            ts_data = self.decrypt_ts(ts_data, segment)
                        
                        ts_path = os.path.join(temp_dir, filename)
                        with open(ts_path, 'wb') as f:
                            f.write(ts_data)
                        
                        with lock:
                            completed_tasks += 1
                            current_downloaded = downloaded_segments + completed_tasks
                            current_progress = (current_downloaded / total_segments) * 100
                            
                            if progress_callback:
                                speed_str = self._format_speed(self.current_speed)
                                progress_callback(current_progress, current_downloaded, total_segments, speed_str)
                            
                            if int(current_progress) > last_progress_update or completed_tasks % 5 == 0:
                                speed_str = self._format_speed(self.current_speed)
                                print(f"ğŸ“Š è¿›åº¦: {current_progress:.1f}% ({current_downloaded}/{total_segments}), é€Ÿåº¦: {speed_str}")
                                last_progress_update = int(current_progress)
                    
                except Exception as e:
                    logger.error(f"åˆ†ç‰‡ä¸‹è½½å¤±è´¥: {str(e)}")
                    task_queue.put((i, segment, filename))
                finally:
                    task_queue.task_done()
        
        # é™åˆ¶å®é™…çº¿ç¨‹æ•°ä¸è¶…è¿‡å‰©ä½™ä»»åŠ¡æ•°
        actual_threads = min(self.max_threads, total_tasks, 20)
        threads = []
        for _ in range(actual_threads):
            t = threading.Thread(target=worker, daemon=True)
            t.start()
            threads.append(t)
        
        for t in threads:
            t.join()
        
        return not self.is_stopped and (completed_tasks > 0 or downloaded_segments == total_segments)

    def _format_speed(self, speed_bytes: float) -> str:
        """æ ¼å¼åŒ–é€Ÿåº¦æ˜¾ç¤º"""
        if speed_bytes <= 0:
            return "0 B/s"
        
        if speed_bytes < 1024:
            return f"{speed_bytes:.1f} B/s"
        elif speed_bytes < 1024 * 1024:
            return f"{speed_bytes/1024:.1f} KB/s"
        else:
            return f"{speed_bytes/(1024*1024):.1f} MB/s"

    def merge_with_ffmpeg(self, ts_files: List[str], output_path: str) -> bool:
        """ä½¿ç”¨FFmpegåˆå¹¶è§†é¢‘"""
        ffmpeg_path = self._get_ffmpeg_path()
        if not ffmpeg_path:
            logger.error("FFmpegæœªæ‰¾åˆ°")
            return False
        
        try:
            filelist_path = os.path.join(os.path.dirname(ts_files[0]), "filelist.txt")
            with open(filelist_path, 'w', encoding='utf-8') as f:
                for tf in ts_files:
                    f.write(f"file '{os.path.basename(tf)}'\n")
            
            cmd = [
                ffmpeg_path,
                '-f', 'concat',
                '-safe', '0',
                '-i', filelist_path,
                '-c', 'copy',
                '-movflags', 'faststart',
                '-y',
                '-loglevel', 'quiet',
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            return result.returncode == 0
                
        except Exception as e:
            logger.error(f"FFmpegåˆå¹¶å¤±è´¥: {str(e)}")
            return False

    def download(self, progress_callback: Optional[Callable] = None, 
                status_callback: Optional[Callable] = None) -> bool:
        """ä¸»ä¸‹è½½æ–¹æ³•"""
        try:
            if status_callback:
                status_callback("è§£æM3U8æ–‡ä»¶...")
            
            print(f"ğŸ”— å¼€å§‹å¤„ç†URL: {self.url}")
            print(f"ğŸ¯ ä½¿ç”¨çº¿ç¨‹æ•°: {self.max_threads}")
            
            # åˆå§‹åŒ–ä¸‹è½½ç»Ÿè®¡
            self.downloaded_bytes = 0
            self.start_time = time.time()
            self.current_speed = 0
            
            # ä¸‹è½½M3U8æ–‡ä»¶
            m3u8_content = self.download_with_retry(self.url)
            if not m3u8_content:
                raise Exception("æ— æ³•ä¸‹è½½M3U8æ–‡ä»¶")
            
            content_text = m3u8_content.decode('utf-8', errors='ignore')
            print(f"ğŸ“„ M3U8å†…å®¹ç±»å‹: {'ä¸»æ’­æ”¾åˆ—è¡¨' if '#EXT-X-STREAM-INF' in content_text else 'åª’ä½“æ’­æ”¾åˆ—è¡¨'}")
            
            # è§£æM3U8
            playlist = m3u8.loads(content_text, uri=self.url)
            actual_url = self.url
            
            # å¤„ç†ä¸»æ’­æ”¾åˆ—è¡¨
            if playlist.is_variant:
                if status_callback:
                    status_callback("é€‰æ‹©æœ€é«˜è´¨é‡æµ...")
                
                print("ğŸ¯ ä¸»æ’­æ”¾åˆ—è¡¨ä¿¡æ¯:")
                for i, pl in enumerate(playlist.playlists):
                    resolution = getattr(pl.stream_info, 'resolution', 'æœªçŸ¥')
                    bandwidth = getattr(pl.stream_info, 'bandwidth', 0)
                    print(f"  {i+1}. åˆ†è¾¨ç‡: {resolution}, å¸¦å®½: {bandwidth//1000}kbps")
                
                if playlist.playlists:
                    selected_playlist = playlist.playlists[0]
                    stream_url = selected_playlist.absolute_uri or urljoin(self.url, selected_playlist.uri)
                    print(f"ğŸ¬ é€‰æ‹©æµ: {stream_url}")
                    
                    stream_content = self.download_with_retry(stream_url)
                    if not stream_content:
                        raise Exception("æ— æ³•ä¸‹è½½åª’ä½“æµ")
                    
                    playlist = m3u8.loads(stream_content.decode('utf-8', errors='ignore'), uri=stream_url)
                    actual_url = stream_url
                    print(f"âœ… åª’ä½“æ’­æ”¾åˆ—è¡¨åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(playlist.segments)} ä¸ªåˆ†ç‰‡")
                else:
                    raise Exception("ä¸»æ’­æ”¾åˆ—è¡¨ä¸­æ— å¯ç”¨æµ")
            
            base_uri = playlist.base_uri or '/'.join(actual_url.split('/')[:-1]) + '/'
            if not base_uri.endswith('/'):
                base_uri += '/'
            
            segments = [seg for seg in playlist.segments if seg.uri]
            print(f"ğŸ“Š æœ‰æ•ˆåˆ†ç‰‡æ•°é‡: {len(segments)}")
            
            if not segments:
                raise Exception("æ— æœ‰æ•ˆåˆ†ç‰‡")
            
            # å¤„ç†åŠ å¯†
            if playlist.keys and any(k for k in playlist.keys if k):
                first_key = next(k for k in playlist.keys if k)
                print(f"ğŸ” æ£€æµ‹åˆ°åŠ å¯†: {first_key.method}")
                self.load_key(first_key.uri, base_uri)
                if status_callback:
                    status_callback("å¤„ç†åŠ å¯†...")
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp(prefix=f"m3u8_{self.task_id}_")
            
            try:
                # ä¸‹è½½åˆ†ç‰‡
                if status_callback:
                    status_callback("ä¸‹è½½åˆ†ç‰‡...")
                
                print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {len(segments)} ä¸ªåˆ†ç‰‡ï¼Œä½¿ç”¨ {self.max_threads} çº¿ç¨‹")
                success = self.download_segments(segments, base_uri, temp_dir, progress_callback)
                
                if not success:
                    raise Exception("ä¸‹è½½è¢«ä¸­æ­¢")
                
                # åˆå¹¶è§†é¢‘
                if status_callback:
                    status_callback("åˆå¹¶è§†é¢‘...")
                
                ts_files = sorted([os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.endswith('.ts')])
                print(f"ğŸ“¦ å‡†å¤‡åˆå¹¶ {len(ts_files)} ä¸ªTSæ–‡ä»¶")
                
                if not ts_files:
                    raise Exception("æ— TSæ–‡ä»¶å¯åˆå¹¶")
                
                os.makedirs(os.path.dirname(self.save_path), exist_ok=True)
                
                # ä½¿ç”¨FFmpegåˆå¹¶
                if not self.merge_with_ffmpeg(ts_files, self.save_path):
                    raise Exception("è§†é¢‘åˆå¹¶å¤±è´¥")
                
                if status_callback:
                    status_callback("ä¸‹è½½å®Œæˆ")
                
                print("ğŸ‰ ä¸‹è½½ä»»åŠ¡åœ†æ»¡å®Œæˆ!")
                return True
                
            finally:
                shutil.rmtree(temp_dir, ignore_errors=True)
                
        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥: {str(e)}")
            if status_callback:
                status_callback(f"å¤±è´¥: {str(e)}")
            return False
